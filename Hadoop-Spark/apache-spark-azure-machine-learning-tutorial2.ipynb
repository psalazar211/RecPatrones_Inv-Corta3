{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Apache-spark-azure-machine-learning-tutorial.\r\n",
        "\r\n",
        "## Apache-spark-azure-machine-learning-tutorial.\r\n",
        "\r\n",
        "En este tutorial, utilizará el aprendizaje automático automatizado en Azure Machine Learning para crear un modelo de regresión para predecir los precios de las tarifas de taxi. Este proceso llega al mejor modelo aceptando datos de entrenamiento y ajustes de configuración, e iterando automáticamente a través de combinaciones de diferentes métodos, modelos y ajustes de hiperparámetros. Este esta badado en https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/spark/apache-spark-azure-machine-learning-tutorial.md\r\n",
        "\r\n",
        "En este tutorial se muestra como:\r\n",
        "- Crear un grupo de Apache Spark sin servidor usando Synapse Studio\r\n",
        "- Descargar los datos mediante Apache Spark y Azure Open Datasets.\r\n",
        "- Transformar y limpiar datos mediante Apache Spark DataFrames.\r\n",
        "- Entrenar un modelo de regresión lineal.\r\n",
        "- Calcular la precisión del modelo.\r\n",
        "\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debido a que los datos sin procesar están en formato Parquet, puede usar el contexto Spark para extraer el archivo directamente a la memoria como un DataFrame. Cree un Spark DataFrame recuperando los datos a través de la API Open Datasets. Aquí, utiliza el esquema Spark DataFrame en las propiedades de lectura para inferir los tipos de datos y el esquema."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blob_account_name = \"azureopendatastorage\"\r\n",
        "blob_container_name = \"nyctlc\"\r\n",
        "blob_relative_path = \"yellow\"\r\n",
        "blob_sas_token = r\"\"\r\n",
        "\r\n",
        "# Allow Spark to read from the blob remotely\r\n",
        "wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\r\n",
        "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\r\n",
        "\r\n",
        "# Spark read parquet; note that it won't load any data yet\r\n",
        "df = spark.read.parquet(wasbs_path)\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T15:55:00.7155504Z",
              "session_start_time": "2024-03-19T15:55:00.7644867Z",
              "execution_start_time": "2024-03-19T15:58:33.935222Z",
              "execution_finish_time": "2024-03-19T15:58:48.484064Z",
              "spark_jobs": null,
              "parent_msg_id": "b10dc8ff-b75b-4a2a-bf18-0dd6ac4aa6de"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 2, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependiendo del tamaño de su grupo de Spark, los datos sin procesar pueden ser demasiado grandes o tardar demasiado en operar con ellos. Puede filtrar estos datos a algo más pequeño, como un mes de datos, utilizando los filtros start_date y end_date. Después de filtrar un DataFrame, también ejecuta la función describe() en el nuevo DataFrame para ver estadísticas resumidas para cada campo.\r\n",
        "\r\n",
        "Según las estadísticas resumidas, puede ver que hay algunas irregularidades en los datos. Por ejemplo, las estadísticas muestran que la distancia mínima de viaje es inferior a 0. Es necesario filtrar estos puntos de datos irregulares."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ingestion filter\r\n",
        "start_date = '2015-01-01 00:00:00'\r\n",
        "end_date = '2015-12-31 00:00:00'\r\n",
        "\r\n",
        "filtered_df = df.filter('tpepPickupDateTime > \"' + start_date + '\" and tpepPickupDateTime< \"' + end_date + '\"')\r\n",
        "\r\n",
        "filtered_df.describe().show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T15:55:00.7793498Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T15:58:48.6192324Z",
              "execution_finish_time": "2024-03-19T16:18:03.7682624Z",
              "spark_jobs": null,
              "parent_msg_id": "a64152e3-b824-49bf-926c-810851d7a694"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+------------+------------+------------------+-----------------+------------------+------------------+------------------+---------------+------------------+------------------+------------------+-------------------+--------------------+------------------+-------------------+------------------+---------+------------------+\n|summary|          vendorID|    passengerCount|      tripDistance|puLocationId|doLocationId|          startLon|         startLat|            endLon|            endLat|        rateCodeId|storeAndFwdFlag|       paymentType|        fareAmount|             extra|             mtaTax|improvementSurcharge|         tipAmount|        tollsAmount|       totalAmount|   puYear|           puMonth|\n+-------+------------------+------------------+------------------+------------+------------+------------------+-----------------+------------------+------------------+------------------+---------------+------------------+------------------+------------------+-------------------+--------------------+------------------+-------------------+------------------+---------+------------------+\n|  count|         145773047|         145773047|         145773047|           0|           0|         145773047|        145773047|         145773047|         145773047|         145773047|      145773047|         145773047|         145773047|         145773047|          145773047|           145773044|         145773047|          145773047|         145773047|145773047|         145773047|\n|   mean|1.5246304963358555|1.6805232520110525|13.161147608721128|        null|        null|-72.80648051050333|40.10748359067677|-72.85319266694555| 40.13416535825792|1.0420784920548447|           null|1.3788731671363088|12.941346115101773|0.3140489149547652| 0.4975625422098779|  0.2983055868096645|1.7291747041486256|0.30795674491209957|16.099537129841572|   2015.0| 6.323777481306267|\n| stddev|0.4993929718779421| 1.333329572250595|19898.261209453103|        null|        null|  9.22188333731101|5.079323673152058| 9.040863011846191| 4.980297369025976|0.6683400197006898|           null|0.4992139999126688|124.74287786270159| 0.529192259341188|0.05011048381334411|0.026088963246796475| 327.2175722627288| 1.6653000573813057| 357.4087942570745|      0.0|3.4405655025101676|\n|    min|                 1|                 0|     -4.08401244E7|        null|        null|-874.0026245117188|-78.1946792602539|-781.8333129882812| -78.1946792602539|                 1|              N|                 1|            -496.0|             -79.0|               -3.0|                -0.3|            -440.0|              -99.0|            -496.3|     2015|                 1|\n|    max|                 2|                 9|     1.986230136E8|        null|        null|172.60000610351562|404.8666687011719|172.60000610351562|483.45001220703125|                99|              Y|                 5|         825998.61|            999.99|               91.0|                2.39|         3950588.8|             1901.4|         3950611.6|     2015|                12|\n+-------+------------------+------------------+------------------+------------+------------+------------------+-----------------+------------------+------------------+------------------+---------------+------------------+------------------+------------------+-------------------+--------------------+------------------+-------------------+------------------+---------+------------------+\n\n"
          ]
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genere funciones a partir del conjunto de datos seleccionando un conjunto de columnas y creando varias funciones basadas en el tiempo desde el campo de fecha y hora de recogida. Filtre los valores atípicos que se identificaron en el paso anterior y luego elimine las últimas columnas porque no son necesarias para el entrenamiento."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "# To make development easier, faster, and less expensive, downsample for now\r\n",
        "sampled_taxi_df = filtered_df.sample(True, 0.001, seed=1234)\r\n",
        "\r\n",
        "taxi_df = sampled_taxi_df.select('vendorID', 'passengerCount', 'tripDistance',  'startLon', 'startLat', 'endLon' \\\r\n",
        "                                , 'endLat', 'paymentType', 'fareAmount', 'tipAmount'\\\r\n",
        "                                , column('puMonth').alias('month_num') \\\r\n",
        "                                , date_format('tpepPickupDateTime', 'hh').alias('hour_of_day')\\\r\n",
        "                                , date_format('tpepPickupDateTime', 'EEEE').alias('day_of_week')\\\r\n",
        "                                , dayofmonth(col('tpepPickupDateTime')).alias('day_of_month')\r\n",
        "                                ,(unix_timestamp(col('tpepDropoffDateTime')) - unix_timestamp(col('tpepPickupDateTime'))).alias('trip_time'))\\\r\n",
        "                        .filter((sampled_taxi_df.passengerCount > 0) & (sampled_taxi_df.passengerCount < 8)\\\r\n",
        "                                & (sampled_taxi_df.tipAmount >= 0)\\\r\n",
        "                                & (sampled_taxi_df.fareAmount >= 1) & (sampled_taxi_df.fareAmount <= 250)\\\r\n",
        "                                & (sampled_taxi_df.tipAmount < sampled_taxi_df.fareAmount)\\\r\n",
        "                                & (sampled_taxi_df.tripDistance > 0) & (sampled_taxi_df.tripDistance <= 200)\\\r\n",
        "                                & (sampled_taxi_df.rateCodeId <= 5)\\\r\n",
        "                                & (sampled_taxi_df.paymentType.isin({\"1\", \"2\"})))\r\n",
        "taxi_df.show(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T15:55:00.823571Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:18:03.8883241Z",
              "execution_finish_time": "2024-03-19T16:19:37.3222213Z",
              "spark_jobs": null,
              "parent_msg_id": "67a164eb-636e-4151-a901-36e9a68b8fd1"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------+------------+------------------+------------------+------------------+------------------+-----------+----------+---------+---------+-----------+-----------+------------+---------+\n|vendorID|passengerCount|tripDistance|          startLon|          startLat|            endLon|            endLat|paymentType|fareAmount|tipAmount|month_num|hour_of_day|day_of_week|day_of_month|trip_time|\n+--------+--------------+------------+------------------+------------------+------------------+------------------+-----------+----------+---------+---------+-----------+-----------+------------+---------+\n|       2|             2|        1.49|-73.99262237548828|  40.7373161315918|-73.98426818847656| 40.75123596191406|          2|      16.0|      0.0|        3|         05|    Tuesday|          10|     1671|\n|       2|             1|        0.58|-73.94739532470703|  40.7716178894043| -73.9542007446289|40.767921447753906|          2|       4.5|      0.0|        3|         11|     Monday|          30|      200|\n|       2|             1|        2.68|-73.94972229003906|40.784576416015625|-73.97443389892578|40.755611419677734|          1|      12.0|      1.3|        3|         07|     Monday|           2|      835|\n|       1|             1|         1.5|-74.00376892089844| 40.74760818481445|-73.98189544677734| 40.74617385864258|          1|       9.0|     0.01|        3|         01|     Sunday|           1|      676|\n|       1|             1|         2.2|    -73.9775390625| 40.78965377807617| -73.9586410522461|    40.76904296875|          2|       8.5|      0.0|        3|         12|     Sunday|          15|      429|\n|       2|             1|        1.94|-73.97604370117188| 40.78387451171875|-73.98649597167969| 40.76076889038086|          1|      11.5|     3.08|        3|         10|  Wednesday|          11|      952|\n|       1|             1|         0.3|-73.98320770263672| 40.75519561767578|-73.98028564453125| 40.76060485839844|          1|       5.5|      1.0|        3|         01|    Tuesday|          31|      396|\n|       2|             5|        1.37| -74.0088119506836|40.711021423339844| -74.0012435913086| 40.72782897949219|          2|       7.5|      0.0|        3|         07|   Thursday|          12|      497|\n|       1|             3|         1.9|-73.98367309570312| 40.76457595825195|-73.96845245361328|  40.7505989074707|          2|       8.5|      0.0|        3|         08|   Saturday|          28|      570|\n|       1|             1|         1.7|-73.96765899658203| 40.75640869140625|-73.97718048095703| 40.73491668701172|          2|       8.5|      0.0|        3|         02|   Saturday|          14|      579|\n+--------+--------------+------------+------------------+------------------+------------------+------------------+-----------+----------+---------+---------+-----------+-----------+------------+---------+\nonly showing top 10 rows\n\n"
          ]
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generar conjuntos de datos de prueba y validación\r\n",
        "Una vez que tenga su conjunto de datos final, puede dividir los datos en conjuntos de entrenamiento y prueba utilizando la función random_split en Spark. Al utilizar las ponderaciones proporcionadas, esta función divide aleatoriamente los datos en el conjunto de datos de entrenamiento para el entrenamiento del modelo y el conjunto de datos de validación para las pruebas."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random split dataset using Spark; convert Spark to pandas\r\n",
        "training_data, validation_data = taxi_df.randomSplit([0.8,0.2], 223)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T15:55:00.8789056Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:19:37.4421757Z",
              "execution_finish_time": "2024-03-19T16:19:37.5908802Z",
              "spark_jobs": null,
              "parent_msg_id": "13a72178-cd77-4812-a338-a3daed1a5cf3"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 5, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conéctese a un área de trabajo de Azure Machine Learning\r\n",
        "En Azure Machine Learning, un área de trabajo es una clase que acepta su suscripción de Azure e información de recursos. También crea un recurso en la nube para monitorear y rastrear las ejecuciones de su modelo. En este paso, creará un objeto de área de trabajo a partir del área de trabajo de Azure Machine Learning existente."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "\r\n",
        "from azureml.core import Experiment, Workspace, Dataset, Datastore\r\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T15:55:00.9646395Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:19:37.7077847Z",
              "execution_finish_time": "2024-03-19T16:20:00.9802485Z",
              "spark_jobs": null,
              "parent_msg_id": "a2658d61-617c-4194-ac62-38b4247aaf28"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 6, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter details of your Azure Machine Learning workspace\r\n",
        "subscription_id = '6317b93a-f64a-41c2-b939-d78a49d7707b'\r\n",
        "resource_group = 'salazarpamela3-rg'\r\n",
        "workspace_name = 'reconocimiento_patrones_inv3'\r\n",
        "experiment_name = \"aml-synapse-regression\"\r\n",
        "\r\n",
        "\r\n",
        "ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\r\n",
        "experiment = Experiment(ws, experiment_name)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T15:55:01.0575938Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:20:01.0999913Z",
              "execution_finish_time": "2024-03-19T16:20:02.9096457Z",
              "spark_jobs": null,
              "parent_msg_id": "db6bdb2c-0e48-4e98-a71b-3de6c9cadbdf"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 7, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = Datastore.get_default(ws)\r\n",
        "dataset = TabularDatasetFactory.register_spark_dataframe(training_data, datastore, name = experiment_name + \"-dataset\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T15:55:01.0997129Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:20:03.0209712Z",
              "execution_finish_time": "2024-03-19T16:26:09.6559148Z",
              "spark_jobs": null,
              "parent_msg_id": "14083847-f23a-43b6-a5cc-7e28fb4c4d77"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method register_spark_dataframe: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nValidating arguments.\nArguments validated.\nWriting spark dataframe to managed-dataset/615c3d14-dd85-4d59-862b-d996a1360627\nCreating new dataset\nRegistering new dataset\nSuccessfully created and registered a new dataset.\n"
          ]
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenar modelo"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\r\n",
        "from pyspark.ml.feature import VectorAssembler\r\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T16:38:37.0938647Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:38:37.2182144Z",
              "execution_finish_time": "2024-03-19T16:38:41.0654969Z",
              "spark_jobs": null,
              "parent_msg_id": "ddf1cd6d-ad1d-454b-b731-ee347c579c64"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 9, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\r\n",
        "    inputCols=[\"passengerCount\",\"tripDistance\",\"startLon\",\"startLat\",\"endLon\",\r\n",
        "                \"endLat\",\"fareAmount\",\"tipAmount\",\"month_num\",\"day_of_month\",\"trip_time\"],\r\n",
        "    outputCol=\"features\")\r\n",
        "\r\n",
        "data = assembler.transform(taxi_df)\r\n",
        "\r\n",
        "\r\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T16:47:21.8291312Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:47:21.9705875Z",
              "execution_finish_time": "2024-03-19T16:47:22.1212969Z",
              "spark_jobs": null,
              "parent_msg_id": "66c607c3-1174-4762-9b00-35ec2d7d0cc9"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 12, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Run"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T16:49:50.674651Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:49:50.7930415Z",
              "execution_finish_time": "2024-03-19T16:49:50.9311157Z",
              "spark_jobs": null,
              "parent_msg_id": "e305a363-3b13-47c9-81d8-229bf22bd015"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 13, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with experiment.start_logging() as run:\r\n",
        "    model_name = \"LinearRegression\"\r\n",
        "    run.log(\"Model Name\",model_name)\r\n",
        "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"fareAmount\", predictionCol=\"predicted_fareAmount\")\r\n",
        "    lr_model = lr.fit(train_data)\r\n",
        "    predictions = lr_model.transform(test_data)\r\n",
        "\r\n",
        "    evaluator = RegressionEvaluator(labelCol=\"fareAmount\", predictionCol=\"predicted_fareAmount\", metricName=\"rmse\")\r\n",
        "    rmse = evaluator.evaluate(predictions)\r\n",
        "    print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse))\r\n",
        "\r\n",
        "    evaluator_r2 = RegressionEvaluator(labelCol=\"fareAmount\", predictionCol=\"predicted_fareAmount\", metricName=\"r2\")\r\n",
        "    r2 = evaluator_r2.evaluate(predictions)\r\n",
        "    print(\"R-squared (R2) on test data: {:.3f}\".format(r2))\r\n",
        "\r\n",
        "    # Log Performance\r\n",
        "    run.log('RMSE', rmse)\r\n",
        "    run.log(\"R2\", r2)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T17:37:47.7466883Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T17:37:47.8569424Z",
              "execution_finish_time": "2024-03-19T17:59:18.9277588Z",
              "spark_jobs": null,
              "parent_msg_id": "8e8ad202-c344-42f7-a329-0d01bf06a900"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 25, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data: 0.000\nR-squared (R2) on test data: 1.000\n"
          ]
        }
      ],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"fareAmount\", predictionCol=\"predicted_fareAmount\")\r\n",
        "lr_model = lr.fit(train_data)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 14,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T16:56:44.1139059Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T16:56:44.2373067Z",
              "execution_finish_time": "2024-03-19T17:07:40.0115968Z",
              "spark_jobs": null,
              "parent_msg_id": "23d185a1-6b77-48e4-addb-c6237f87a31c"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 14, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr_model.transform(test_data)\r\n",
        "\r\n",
        "evaluator = RegressionEvaluator(labelCol=\"fareAmount\", predictionCol=\"predicted_fareAmount\", metricName=\"rmse\")\r\n",
        "rmse = evaluator.evaluate(predictions)\r\n",
        "print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse))\r\n",
        "\r\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"fareAmount\", predictionCol=\"predicted_fareAmount\", metricName=\"r2\")\r\n",
        "r2 = evaluator_r2.evaluate(predictions)\r\n",
        "print(\"R-squared (R2) on test data: {:.3f}\".format(r2))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "recopatrspark",
              "session_id": "16",
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-03-19T17:08:14.3697231Z",
              "session_start_time": null,
              "execution_start_time": "2024-03-19T17:08:14.4854733Z",
              "execution_finish_time": "2024-03-19T17:19:12.5662566Z",
              "spark_jobs": null,
              "parent_msg_id": "39a37dcb-4d9a-48d6-ab74-7795c21182dd"
            },
            "text/plain": "StatementMeta(recopatrspark, 16, 15, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data: 0.000\nR-squared (R2) on test data: 1.000\n"
          ]
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}